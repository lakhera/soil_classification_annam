{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473a1b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T18:44:30.308936Z",
     "iopub.status.busy": "2025-05-24T18:44:30.308590Z",
     "iopub.status.idle": "2025-05-24T18:47:24.991197Z",
     "shell.execute_reply": "2025-05-24T18:47:24.990120Z"
    },
    "papermill": {
     "duration": 174.686672,
     "end_time": "2025-05-24T18:47:24.992417",
     "exception": false,
     "start_time": "2025-05-24T18:44:30.305745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 175MB/s]\n",
      "100%|██████████| 31/31 [00:08<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 13.1130, Train Acc: 0.8516, Val Loss: 0.4137, Val Acc: 0.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 7.8265, Train Acc: 0.9140, Val Loss: 0.2577, Val Acc: 0.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 6.1393, Train Acc: 0.9273, Val Loss: 0.3401, Val Acc: 0.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 5.9220, Train Acc: 0.9345, Val Loss: 0.4268, Val Acc: 0.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 4.7385, Train Acc: 0.9468, Val Loss: 0.1700, Val Acc: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 3.4969, Train Acc: 0.9550, Val Loss: 0.1254, Val Acc: 0.9592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 2.5119, Train Acc: 0.9683, Val Loss: 0.1073, Val Acc: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 2.0039, Train Acc: 0.9754, Val Loss: 0.1142, Val Acc: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.6485, Train Acc: 0.9775, Val Loss: 0.1324, Val Acc: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 1.6313, Train Acc: 0.9816, Val Loss: 0.1114, Val Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 1.1831, Train Acc: 0.9877, Val Loss: 0.1076, Val Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 1.6699, Train Acc: 0.9816, Val Loss: 0.1050, Val Acc: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 1.1599, Train Acc: 0.9887, Val Loss: 0.1037, Val Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 1.0887, Train Acc: 0.9887, Val Loss: 0.1054, Val Acc: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 1.1145, Train Acc: 0.9877, Val Loss: 0.1063, Val Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 1.1780, Train Acc: 0.9887, Val Loss: 0.1036, Val Acc: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 1.0715, Train Acc: 0.9918, Val Loss: 0.1110, Val Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 1.0722, Train Acc: 0.9867, Val Loss: 0.1032, Val Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 1.1301, Train Acc: 0.9846, Val Loss: 0.1176, Val Acc: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 1.2637, Train Acc: 0.9877, Val Loss: 0.1071, Val Acc: 0.9755\n",
      "Best model saved with validation accuracy: 0.9755102040816327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 11/11 [00:03<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              image_id      soil_type\n",
      "0    img_cdf80d6f.jpeg  Alluvial soil\n",
      "1     img_c0142a80.jpg  Alluvial soil\n",
      "2     img_91168fb0.jpg  Alluvial soil\n",
      "3     img_9822190f.jpg  Alluvial soil\n",
      "4    img_e5fc436c.jpeg  Alluvial soil\n",
      "..                 ...            ...\n",
      "336   img_bc768d49.jpg     Black Soil\n",
      "337   img_ddef2a37.jpg     Black Soil\n",
      "338   img_be2e7e88.jpg     Black Soil\n",
      "339   img_04f21bb9.jpg     Black Soil\n",
      "340   img_02c09374.jpg     Black Soil\n",
      "\n",
      "[341 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Soil Image Classification Challenge\n",
    "# The Soil Image Classification Challenge is a machine learning competition organised by Annam.ai at IIT Ropar, serving as an initial task for shortlisted hackathon participants. Competitors will build models to classify each soil image into one of four categories: Alluvial soil, Black soil, Clay soil, or Red soil. Final submissions are due by May 25, 2025, 11:59 PM IST. Be sure to submit well before the deadline to avoid server overload or last-minute issues.\n",
    "# Task: Classify each provided soil image into one of the four soil types (Alluvial, Black, Clay, Red).\n",
    "# Deadline: May 25, 2025, 11:59 PM IST\n",
    "# Team Name: RootCoders (Amit Lakhera, Vikramjeet, Jyoti Ghungru, Pradipta Das, Sukanya Saha)\n",
    "# Last Modified: May 25, 2025\n",
    "# -------------------------\n",
    "\n",
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# Sklearn for splitting and label encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load and Prepare Data\n",
    "train_df = pd.read_csv('/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv')\n",
    "train_df['image'] = train_df['image_id']\n",
    "train_df['label'] = train_df['soil_type']\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df['label_encoded'] = le.fit_transform(train_df['label'])\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label_encoded'], random_state=42)\n",
    "\n",
    "# Image Transformations\n",
    "img_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Custom Dataset Classes\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.loc[idx, 'image']\n",
    "        label = self.df.loc[idx, 'label_encoded']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_img_dir = '/kaggle/input/soil-classification/soil_classification-2025/train/'\n",
    "train_dataset = SoilDataset(train_df, train_img_dir, transform=train_transforms)\n",
    "val_dataset = SoilDataset(val_df, train_img_dir, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, data_loader, criterion=None):\n",
    "    model.eval()\n",
    "    correct, total, val_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            if criterion:\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    avg_loss = val_loss / len(data_loader) if criterion else None\n",
    "    return acc, avg_loss\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_acc = correct / total\n",
    "        val_acc, val_loss = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                  f\"Loss: {running_loss:.4f}, \"\n",
    "                  f\"Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "    torch.save(best_model_state, 'best_model.pth')\n",
    "    print(\"Best model saved with validation accuracy:\", best_acc)\n",
    "\n",
    "# Train the Model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
    "\n",
    "# Load Test Data and Create Submission\n",
    "test_df = pd.read_csv('/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv')\n",
    "test_df['image'] = test_df['image_id']\n",
    "test_img_dir = '/kaggle/input/soil-classification/soil_classification-2025/test/'\n",
    "\n",
    "# Define class TestSoilDataset\n",
    "class TestSoilDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.loc[idx, 'image']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name\n",
    "\n",
    "test_dataset = TestSoilDataset(test_df, test_img_dir, transform=val_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Generate Predictions\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_names in tqdm(test_loader, desc=\"Validation\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(zip(image_names, predicted.cpu().numpy()))\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=['image_id', 'label_encoded'])\n",
    "submission_df['soil_type'] = le.inverse_transform(submission_df['label_encoded'])\n",
    "submission_df = submission_df[['image_id', 'soil_type']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(submission_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12375409,
     "sourceId": 102672,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 182.308547,
   "end_time": "2025-05-24T18:47:28.415777",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-24T18:44:26.107230",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
